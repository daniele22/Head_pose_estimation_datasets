# üìé Head Pose Estimation Datasets
In order to truly make progress in the problem of predicting pose from image intensities, real datasets which contain precise pose annotations, numerous identities, different lighting conditions, all of this across large poses occur.
Most of the HPE models are evaluated using publicly available datasets. These datasets significantly evolved during the last years, especially in terms of complexity of environmental conditions.
Head pose datasets can be categorized by different aspects, such as imaging characteristics (e.g. RGB, grayscale, depth, infrared images), data diversity (e.g. head pose angles ranges, or number of degrees of freedom), acquisition scenario (e.g. in laboratory vs in-the-wild), annotation type, and annotation technique.

This list contains the datasets used in the literature for the head pose estimation task:

- 300W-LP: https://www.tensorflow.org/datasets/catalog/the300w\_lp <br/>
paper: https://arxiv.org/abs/1511.07212
- AFLW: https://www.tugraz.at/institute/icg/research/team-bischof/lrs/downloads/aflw/ <br/>
paper: https://ieeexplore.ieee.org/abstract/document/6130513
- AFLW2000-3D: https://www.tensorflow.org/datasets/catalog/aflw2k3d <br/>
paper: https://arxiv.org/abs/1511.07212
- AFW: https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/ <br/>
paper: https://ieeexplore.ieee.org/abstract/document/6248014
- AISL: http://www.aisl.cs.tut.ac.jp/dataset\_head\_orientation.html <br/>
paper: https://ieeexplore.ieee.org/abstract/document/7380830
- AutoPOSE: https://autopose.dfki.de/ <br/>
paper: https://www.researchgate.net/profile/Mohamed-Selim-12/publication/340042088_AutoPOSE_Large-scale_Automotive_Driver_Head_Pose_and_Gaze_Dataset_with_Deep_Head_Orientation_Baseline/links/5e7877b3a6fdcccd62192067/AutoPOSE-Large-scale-Automotive-Driver-Head-Pose-and-Gaze-Dataset-with-Deep-Head-Orientation-Baseline.pdf
- BioVid Heat Pain: https://www.iikt.ovgu.de/BioVid.html <br/>
paper: https://ieeexplore.ieee.org/abstract/document/6617456
- BIWI Kinect: https://www.kaggle.com/kmader/biwi-kinect-head-pose-database <br/>
paper: https://link.springer.com/chapter/10.1007/978-3-642-23123-0_11
- BJUT-3D: http://www.bjpu.edu.cn/sci/multimedia/mul-lab/3dface/facedatabase.htm <br/>
paper: https://crad.ict.ac.cn/EN/abstract/abstract1023.shtml
- Bosphorus: http://bosphorus.ee.boun.edu.tr/default.aspx <br/>
paper: https://link.springer.com/chapter/10.1007/978-3-540-89991-4_6
- BU: https://www.cs.bu.edu/groups/ivc/HeadTracking/Home.html <br/>
paper: https://ieeexplore.ieee.org/document/845375
- CAS-PEAL: http://www.jdl.ac.cn/peal <br/>
paper: https://ieeexplore.ieee.org/abstract/document/4404053
- CAVE (Columbia Gaze): https://www.cs.columbia.edu/CAVE/databases/columbia\_gaze/ <br/>
paper: https://dl.acm.org/doi/abs/10.1145/2501988.2501994
- CCNU <br/>
paper: https://www.sciencedirect.com/science/article/pii/S0925231215010413
- CMU Multi-Pie: https://www.cs.cmu.edu/afs/cs/project/PIE/MultiPie/Multi-Pie/Home.html <br/>
paper: https://www.sciencedirect.com/science/article/pii/S0262885609001711
- CMU Panoptic: http://domedb.perception.cs.cmu.edu/ <br/>
paper: https://openaccess.thecvf.com/content_iccv_2015/papers/Joo_Panoptic_Studio_A_ICCV_2015_paper.pdf <br/>
Database processed for head pose: https://github.com/Ascend-Research/HeadPoseEstimation-WHENet/issues/13
- CMU-Pie: https://www.ri.cmu.edu/project/pie-database/ <br/>
paper: https://www.ri.cmu.edu/pub_files/pub2/sim_terence_2001_1/sim_terence_2001_1.pdf
- Dali3DHP <br/>
paper: https://ieeexplore.ieee.org/document/6977105
- DD-Pose: https://dd-pose-dataset.tudelft.nl/eval/ <br/>
paper: https://ieeexplore.ieee.org/abstract/document/8814103
- DriveAHead: https://cvhci.anthropomatik.kit.edu/~aschwarz/driveahead/ <br/>
paper: https://openaccess.thecvf.com/content_cvpr_2017_workshops/w13/html/Schwarz_DriveAHead_-_A_CVPR_2017_paper.html
- ETH: https://data.vision.ee.ethz.ch/cvl/vision2/datasets/headposeCVPR08/ <br/>
paper: https://ieeexplore.ieee.org/document/4587807
- FacePix: https://cubic.asu.edu/content/facepix-database <br/>
paper: https://ieeexplore.ieee.org/document/1415348
- GI4E-HP: http://www.unavarra.es/gi4e/databases?languageId=1 <br/>
paper: https://dl.acm.org/doi/10.5555/2951132.2951428
- GOTCHA-I: https://gotchaproject.github.io/ <br/>
paper: https://link.springer.com/chapter/10.1007/978-981-15-4825-3_17
- ICT-3DHP: http://multicomp.cs.cmu.edu/resources/ict-3d-headpose-database-2/ <br/>
paper: https://ieeexplore.ieee.org/document/6247980
- IDIAP Head Pose: https://www.idiap.ch/en/dataset/headpose <br/>
paper: http://publications.idiap.ch/index.php/publications/show/349
- M2FPA: https://pp2li.github.io/M2FPA-dataset/ <br/>
paper: https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_M2FPA_A_Multi-Yaw_Multi-Pitch_High-Quality_Dataset_and_Benchmark_for_Facial_ICCV_2019_paper.pdf
- McGill: https://sites.google.com/site/meltemdemirkus/mcgill-unconstrained-face-video-database <br/>
paper: https://link.springer.com/article/10.1007\%2Fs11042-012-1352-1
- MDM Corpus: https://ecs.utdallas.edu/research/researchlabs/msp-lab/MDM.html <br/>
paper: https://ieeexplore.ieee.org/abstract/document/9507390
- MTFL: http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html <br/>
paper: http://personal.ie.cuhk.edu.hk/~ccloy/files/eccv_2014_deepfacealign.pdf
- Pandora: https://aimagelab.ing.unimore.it/pandora/ <br/>
paper: https://openaccess.thecvf.com/content_cvpr_2017/papers/Borghi_POSEidon_Face-From-Depth_for_CVPR_2017_paper.pdf
- Pointing'04: http://crowley-coutaz.fr/Head\%20Pose\%20Image\%20Database.html <br/>
paper: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.381.3419&rep=rep1&type=pdf
- SASE: https://icv.tuit.ut.ee/databases/ <br/>
paper: https://ieeexplore.ieee.org/document/7961825
- SyLaHP: https://www.iikt.ovgu.de/LmHeadPoseEstBench.html <br/>
paper: https://ieeexplore.ieee.org/abstract/document/8297015
- SynHead: http://www.tnt.uni-hannover.de/papers/view\_paper.php?id=1419 <br/>
paper: https://openaccess.thecvf.com/content_cvpr_2017/html/Gu_Dynamic_Facial_Analysis_CVPR_2017_paper.html
- Synthetic: https://liangwei-bit.github.io/web/project/icip16\_headpose/ <br/>
paper: https://ieeexplore.ieee.org/document/7532566
- Taiwan RoboticsLab: http://robotics.csie.ncku.edu.tw/Databases/FaceDetect\_PoseEstimate.htm <br/>
paper: https://www.researchgate.net/publication/222079557_A_view-based_statistical_system_for_multi-view_face_detection_and_pose_estimation
- UbiPose: https://www.idiap.ch/en/dataset/ubipose <br/>
paper: https://www.idiap.ch/~odobez/publications/YuFunesOdobez-PAMI2018.pdf
- UET-Headpose <br/>
paper: https://arxiv.org/abs/2111.07039?context=cs.HC
- UMD Faces: http://umdfaces.io/ <br/>
paper: https://arxiv.org/pdf/1611.01484.pdf
- VGGFace2: https://github.com/ox-vgg/vgg\_face2 <br/>
paper: https://ieeexplore.ieee.org/abstract/document/8373813

![alt text](/img/datasets_table.jpg)

For more details about each dataset, or acquisition methods refer to TODO.
In this paper you can also find details on methods for head pose estimation, evaluation metrics, evaluation pipeline and results obtained on commonly used datasets.


# ‚úçÔ∏è Author   
**[Daniele Filippini]**
